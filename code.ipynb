{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2gjYjVD97g-",
        "outputId": "0583cf03-4e55-464e-db36-86c4839f3667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
            "Classification Result: The tooth is worn\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load pre-trained VGG16 model (excluding the fully connected layers)\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Load and preprocess the reference image\n",
        "reference_image_path = '/content/tooth.jpeg'\n",
        "reference_image = cv2.imread(reference_image_path)\n",
        "reference_image = cv2.resize(reference_image, (224, 224))  # Resize to VGG16 input size\n",
        "reference_image = preprocess_input(reference_image.astype(np.float32))  # Preprocess input for VGG16\n",
        "\n",
        "# Extract features from the reference image using the pre-trained model\n",
        "reference_features = vgg_model.predict(np.expand_dims(reference_image, axis=0))\n",
        "\n",
        "def classify_similarity(new_image_path, threshold=0.8):\n",
        "    # Load and preprocess the new image\n",
        "    new_image = cv2.imread(new_image_path)\n",
        "    new_image = cv2.resize(new_image, (224, 224))  # Resize to VGG16 input size\n",
        "    new_image = preprocess_input(new_image.astype(np.float32))  # Preprocess input for VGG16\n",
        "\n",
        "    # Extract features from the new image using the pre-trained model\n",
        "    new_image_features = vgg_model.predict(np.expand_dims(new_image, axis=0))\n",
        "\n",
        "    # Compute cosine similarity between the reference and new image features\n",
        "    similarity_score = cosine_similarity(reference_features.reshape(1, -1), new_image_features.reshape(1, -1))\n",
        "\n",
        "    # Classify the new image based on the similarity score and threshold\n",
        "    if similarity_score >= threshold:\n",
        "        return \"The tooth is in good condition\"\n",
        "    else:\n",
        "        return \"The tooth is worn\"\n",
        "\n",
        "#testing the other picture\n",
        "new_image_path = '/content/worntooth.jpeg'\n",
        "classification_result = classify_similarity(new_image_path, threshold=0.8)\n",
        "print(\"Classification Result:\", classification_result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ac6soIj-7Jz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}